# Phase 6 Implementation Prompt: Testing and Documentation

## Objective

Create comprehensive test suite with fixtures, achieve 80%+ code coverage, and write user-facing documentation for installation, usage, and CI/CD integration.

## Context

This final phase ensures production readiness through thorough testing and clear documentation. Tests use pytest with mocked LLM providers to avoid API calls. Documentation focuses on practical workflows and common use cases.

## Specifications to Reference

Read these specification files before starting:
- `specifications/09-TESTING.md` - Testing strategy and requirements
- `specifications/00-OVERVIEW.md` - Overall architecture for documentation context

## Tasks

### Task 1: Test Fixtures

Create `tests/fixtures/` directory and populate with Azure What-If output samples:

#### Step 1.1: create_only.txt

**Content:** What-If output showing only Create operations

```
Resource and property changes are indicated with this symbol:
  + Create
  ~ Modify
  - Delete
  = NoChange
  * Ignore

The deployment will update the following scope:

Scope: /subscriptions/12345678-1234-1234-1234-123456789012/resourceGroups/rg-example

  + Microsoft.ApiManagement/service/diagnostics/applicationinsights [2023-03-01-preview]

      id:           "/subscriptions/12345.../diagnostics/applicationinsights"
      location:     "eastus"
      name:         "applicationinsights"
      properties.alwaysLog:             "allErrors"
      properties.logClientIp:           true
      type:         "Microsoft.ApiManagement/service/diagnostics"

  + Microsoft.ApiManagement/service/policies/policyFragments/parse-jwt [2023-03-01-preview]

      id:           "/subscriptions/12345.../policyFragments/parse-jwt"
      name:         "parse-jwt"
      type:         "Microsoft.ApiManagement/service/policies/policyFragments"

  + Microsoft.Insights/components/appinsights [2020-02-02]

      id:           "/subscriptions/12345.../components/appinsights"
      kind:         "web"
      location:     "eastus"
      name:         "appinsights"
      type:         "Microsoft.Insights/components"

Resource changes: 3 to create.
```

**Purpose:** Test basic create-only scenarios, action detection, simple rendering

#### Step 1.2: mixed_changes.txt

**Content:** Mix of Create, Modify, Delete operations

```
Resource and property changes are indicated with this symbol:
  + Create
  ~ Modify
  - Delete

The deployment will update the following scope:

Scope: /subscriptions/12345678-1234-1234-1234-123456789012/resourceGroups/rg-example

  + Microsoft.Storage/storageAccounts/newstorage [2023-01-01]

      id:           "/subscriptions/12345.../storageAccounts/newstorage"
      kind:         "StorageV2"
      location:     "eastus"

  ~ Microsoft.Network/virtualNetworks/myvnet [2023-05-01]

      ~ properties.subnets[0].properties.addressPrefix: "10.0.1.0/24" => "10.0.1.0/25"

  ~ Microsoft.ApiManagement/service/myapi [2023-03-01-preview]

      ~ properties.publicIPAddressConfiguration.enabled: false => true

  - Microsoft.Sql/servers/databases/testdb [2023-05-01]

      id:         "/subscriptions/12345.../databases/testdb"
      name:       "testdb"
      type:       "Microsoft.Sql/servers/databases"

  - Microsoft.KeyVault/vaults/myvault [2023-02-01]

      id:         "/subscriptions/12345.../vaults/myvault"
      location:   "eastus"
      name:       "myvault"

Resource changes: 1 to create, 2 to modify, 2 to delete.
```

**Purpose:** Test comprehensive rendering, risk assessment, multiple action types

#### Step 1.3: deletes.txt

**Content:** Only deletion operations

```
Resource and property changes are indicated with this symbol:
  - Delete

The deployment will update the following scope:

  - Microsoft.Sql/servers/databases/production-db [2023-05-01]

      id:         "/subscriptions/12345.../databases/production-db"
      name:       "production-db"

  - Microsoft.Storage/storageAccounts/prodlogs [2023-01-01]

      id:         "/subscriptions/12345.../storageAccounts/prodlogs"
      kind:       "StorageV2"

  - Microsoft.KeyVault/vaults/production-vault [2023-02-01]

      id:         "/subscriptions/12345.../vaults/production-vault"

Resource changes: 3 to delete.
```

**Purpose:** Test high-risk operation detection, deletion handling

#### Step 1.4: no_changes.txt

**Content:** Only NoChange and Ignore operations

```
Resource and property changes are indicated with this symbol:
  = NoChange
  * Ignore

The deployment will update the following scope:

  = Microsoft.ApiManagement/service/myapi [2023-03-01-preview]

      id:         "/subscriptions/12345.../myapi"

  * Microsoft.Network/virtualNetworks/myvnet [2023-05-01]

      id:         "/subscriptions/12345.../myvnet"

Resource changes: 1 no change, 1 to ignore.
```

**Purpose:** Test filtering, empty result handling

#### Step 1.5: large_output.txt

**Content:** Generate programmatically with 50+ resources

Create `tests/fixtures/generate_large_fixture.py`:

```python
"""Generate large fixture for testing truncation and performance."""

def generate_large_fixture():
    output = """Resource and property changes are indicated with this symbol:
  + Create
  ~ Modify

The deployment will update the following scope:

"""
    for i in range(60):
        output += f"""  + Microsoft.Storage/storageAccounts/storage{i:03d} [2023-01-01]

      id:           "/subscriptions/12345.../storageAccounts/storage{i:03d}"
      kind:         "StorageV2"
      location:     "eastus"
      name:         "storage{i:03d}"

"""
    output += f"\nResource changes: 60 to create.\n"
    return output

if __name__ == "__main__":
    with open("large_output.txt", "w") as f:
        f.write(generate_large_fixture())
    print("Generated large_output.txt")
```

**Purpose:** Test performance, truncation, large table rendering

### Task 2: Unit Tests

#### Step 2.1: Test Input Module

Create `tests/test_input.py`:

```python
"""Tests for input validation."""

import pytest
from io import StringIO
from bicep_whatif_advisor.input import read_stdin, InputError


def test_validate_whatif_valid(mocker):
    """Test valid What-If output."""
    whatif_output = "Resource changes:\n+ Create\n  Microsoft.Storage/storageAccounts/test"
    mocker.patch('sys.stdin', StringIO(whatif_output))
    mocker.patch('sys.stdin.isatty', return_value=False)

    result = read_stdin()
    assert "Resource changes:" in result
    assert len(result) > 0


def test_validate_whatif_invalid(mocker):
    """Test invalid input without What-If markers."""
    invalid_output = "This is just plain text without any What-If markers"
    mocker.patch('sys.stdin', StringIO(invalid_output))
    mocker.patch('sys.stdin.isatty', return_value=False)

    with pytest.raises(InputError, match="does not appear to be Azure What-If output"):
        read_stdin()


def test_detect_tty(mocker):
    """Test TTY detection (no piped input)."""
    mocker.patch('sys.stdin.isatty', return_value=True)

    with pytest.raises(InputError, match="No input provided"):
        read_stdin()


def test_truncation(mocker):
    """Test input truncation for large output."""
    large_output = "Resource changes:\n" + ("x" * 110000)
    mocker.patch('sys.stdin', StringIO(large_output))
    mocker.patch('sys.stdin.isatty', return_value=False)

    result = read_stdin()
    assert len(result) == 100000


def test_empty_input(mocker):
    """Test empty input."""
    mocker.patch('sys.stdin', StringIO(""))
    mocker.patch('sys.stdin.isatty', return_value=False)

    with pytest.raises(InputError):
        read_stdin()
```

#### Step 2.2: Test Prompt Module

Already covered in Phase 2, but ensure comprehensive tests exist.

#### Step 2.3: Test Render Module

Already covered in Phase 2, but add tests for low-confidence display.

#### Step 2.4: Test CLI Module

Create `tests/test_cli.py`:

```python
"""Tests for CLI module."""

import pytest
import json
from bicep_whatif_advisor.cli import extract_json, filter_by_confidence


def test_extract_json_valid():
    """Test extracting valid JSON."""
    response = '{"resources": [], "overall_summary": "test"}'
    result = extract_json(response)
    assert result["resources"] == []


def test_extract_json_with_text():
    """Test extracting JSON with surrounding text."""
    response = 'Here is the analysis:\n{"resources": [], "overall_summary": "test"}\nThat is all.'
    result = extract_json(response)
    assert result["resources"] == []


def test_extract_json_nested():
    """Test extracting nested JSON."""
    response = '{"resources": [{"nested": {"key": "value"}}], "overall_summary": "test"}'
    result = extract_json(response)
    assert result["resources"][0]["nested"]["key"] == "value"


def test_extract_json_invalid():
    """Test error on invalid JSON."""
    response = "This is not JSON at all"
    with pytest.raises(ValueError, match="No JSON object found"):
        extract_json(response)


def test_filter_by_confidence():
    """Test confidence-based filtering."""
    data = {
        "resources": [
            {"resource_name": "r1", "confidence_level": "high"},
            {"resource_name": "r2", "confidence_level": "low"},
            {"resource_name": "r3", "confidence_level": "medium"},
            {"resource_name": "r4", "confidence_level": "noise"},
        ],
        "overall_summary": "test",
        "risk_assessment": {"drift": {"risk_level": "low"}},
        "verdict": {"safe": True}
    }

    high_conf, low_conf = filter_by_confidence(data)

    assert len(high_conf["resources"]) == 2  # high and medium
    assert len(low_conf["resources"]) == 2   # low and noise
    assert "risk_assessment" in high_conf
    assert "verdict" in high_conf
```

### Task 3: Integration Tests

Create `tests/test_integration.py`:

```python
"""End-to-end integration tests."""

import pytest
from unittest.mock import Mock
from click.testing import CliRunner
from bicep_whatif_advisor.cli import main


def test_e2e_standard_mode(mocker):
    """Test complete standard mode flow."""
    # Mock provider
    mock_provider = Mock()
    mock_provider.complete.return_value = '''{
        "resources": [
            {
                "resource_name": "test-storage",
                "resource_type": "Storage Account",
                "action": "Create",
                "summary": "Creates new storage account",
                "confidence_level": "high",
                "confidence_reason": "New resource creation"
            }
        ],
        "overall_summary": "1 create: Adds storage account"
    }'''
    mocker.patch('bicep_whatif_advisor.providers.get_provider', return_value=mock_provider)

    # Mock stdin
    with open('tests/fixtures/create_only.txt', 'r') as f:
        fixture_content = f.read()
    mocker.patch('bicep_whatif_advisor.input.read_stdin', return_value=fixture_content)

    # Run CLI
    runner = CliRunner()
    result = runner.invoke(main, ['--format', 'table'])

    assert result.exit_code == 0
    assert mock_provider.complete.called


def test_e2e_ci_mode_safe(mocker):
    """Test CI mode with safe deployment."""
    # Mock platform detection
    from bicep_whatif_advisor.ci.platform import PlatformContext
    mock_ctx = PlatformContext(
        platform="github",
        pr_number="123",
        pr_title="Add monitoring",
        base_branch="main"
    )
    mocker.patch('bicep_whatif_advisor.ci.platform.detect_platform', return_value=mock_ctx)

    # Mock git diff
    mocker.patch('bicep_whatif_advisor.ci.diff.get_diff', return_value="diff content")

    # Mock provider
    mock_provider = Mock()
    mock_provider.complete.return_value = '''{
        "resources": [],
        "overall_summary": "No changes",
        "risk_assessment": {
            "drift": {"risk_level": "low", "concerns": [], "reasoning": "All safe"},
            "intent": {"risk_level": "low", "concerns": [], "reasoning": "Aligned"},
            "operations": {"risk_level": "low", "concerns": [], "reasoning": "No risk"}
        },
        "verdict": {
            "safe": true,
            "highest_risk_bucket": "none",
            "overall_risk_level": "low",
            "reasoning": "All risk buckets within thresholds"
        }
    }'''
    mocker.patch('bicep_whatif_advisor.providers.get_provider', return_value=mock_provider)

    # Mock stdin
    mocker.patch('bicep_whatif_advisor.input.read_stdin', return_value="Resource changes:\n+ Create")

    # Run CLI
    runner = CliRunner()
    result = runner.invoke(main, ['--ci'])

    assert result.exit_code == 0
    assert "SAFE" in result.output


def test_e2e_noise_filtering(mocker, tmp_path):
    """Test noise filtering workflow."""
    # Create noise patterns file
    noise_file = tmp_path / "patterns.txt"
    noise_file.write_text("Computed property\nMetadata update\n")

    # Mock provider
    mock_provider = Mock()
    mock_provider.complete.return_value = '''{
        "resources": [
            {
                "resource_name": "subnet",
                "resource_type": "Subnet",
                "action": "Modify",
                "summary": "Computed property change",
                "confidence_level": "medium",
                "confidence_reason": "Uncertain"
            }
        ],
        "overall_summary": "1 modify"
    }'''
    mocker.patch('bicep_whatif_advisor.providers.get_provider', return_value=mock_provider)

    # Mock stdin
    mocker.patch('bicep_whatif_advisor.input.read_stdin', return_value="Resource changes:\n~ Modify")

    # Run CLI
    runner = CliRunner()
    result = runner.invoke(main, ['--noise-filter', str(noise_file)])

    assert result.exit_code == 0
```

### Task 4: Test Configuration

Update `pyproject.toml` to include pytest configuration:

```toml
[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "-v",
    "--strict-markers",
    "--tb=short",
]
markers = [
    "unit: Unit tests",
    "integration: Integration tests",
    "slow: Slow tests requiring external resources",
]
```

### Task 5: Documentation

#### Step 5.1: README.md

Create comprehensive `README.md`:

```markdown
# bicep-whatif-advisor

AI-powered Azure Bicep What-If deployment advisor with automated CI/CD safety reviews.

## Overview

bicep-whatif-advisor analyzes Azure What-If deployment output using LLMs (Anthropic Claude, Azure OpenAI, or Ollama) to provide:

- **Human-friendly summaries** of infrastructure changes
- **Automated deployment safety reviews** for CI/CD pipelines
- **Three-bucket risk assessment** (drift, intent, operations)
- **Azure What-If noise filtering** with confidence scoring
- **PR comment integration** for GitHub Actions and Azure DevOps

## Quick Start

### Installation

```bash
# Install with Anthropic Claude support (recommended)
pip install bicep-whatif-advisor[anthropic]

# Or with all provider support
pip install bicep-whatif-advisor[all]
```

### Basic Usage

```bash
# Set API key
export ANTHROPIC_API_KEY=your-api-key

# Analyze What-If output
az deployment group what-if -g my-rg -f main.bicep | bicep-whatif-advisor
```

### CI/CD Deployment Gate

```bash
# Run in CI mode with automatic platform detection
az deployment group what-if ... | bicep-whatif-advisor --ci --post-comment
```

## Features

### Standard Mode

Converts What-If output into human-readable summaries:

```
â•­â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ # â”‚ Resource             â”‚ Type                â”‚ Action â”‚ Summary                         â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1 â”‚ appinsights-logger   â”‚ APIM Logger         â”‚ âœ… Create â”‚ Creates Application Insights   â”‚
â”‚ 2 â”‚ parse-jwt-fragment   â”‚ Policy Fragment     â”‚ âœ… Create â”‚ Adds JWT authentication policy â”‚
â•°â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

### CI Mode: Three-Bucket Risk Assessment

Evaluates deployment safety across independent risk dimensions:

1. **Infrastructure Drift**: Detects changes not in your code diff (out-of-band modifications)
2. **PR Intent Alignment**: Compares changes to PR title/description to catch unintended scope
3. **Risky Operations**: Flags inherently dangerous operations (deletions, security changes)

Each bucket has independent configurable thresholds. Deployment fails if ANY bucket exceeds its threshold.

### Noise Filtering

Filters Azure What-If noise using:
- **LLM confidence scoring**: Automatically identifies low-confidence changes
- **Pattern matching**: User-defined patterns for additional filtering

## Documentation

- [Getting Started Guide](docs/guides/GETTING_STARTED.md) - Installation and first steps
- [CI/CD Integration](docs/guides/CICD_INTEGRATION.md) - GitHub Actions, Azure DevOps setup
- [Risk Assessment](docs/guides/RISK_ASSESSMENT.md) - Understanding the three-bucket system
- [CLI Reference](docs/guides/CLI_REFERENCE.md) - Complete command documentation

## Examples

### Standard Mode

```bash
# Table output (default)
az deployment group what-if ... | bicep-whatif-advisor

# JSON output
az deployment group what-if ... | bicep-whatif-advisor --format json

# Verbose mode (property-level changes)
az deployment group what-if ... | bicep-whatif-advisor --verbose
```

### CI Mode

```bash
# Strict mode (fail on any medium/high risk)
az deployment group what-if ... | bicep-whatif-advisor --ci \
  --drift-threshold medium \
  --intent-threshold medium \
  --operations-threshold medium

# With noise filtering
az deployment group what-if ... | bicep-whatif-advisor --ci \
  --noise-filter patterns.txt \
  --post-comment
```

## Supported LLM Providers

- **Anthropic Claude** (recommended): `--provider anthropic`
- **Azure OpenAI**: `--provider azure-openai`
- **Ollama** (local): `--provider ollama`

## License

MIT

## Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.
```

#### Step 5.2: docs/guides/GETTING_STARTED.md

Create user guide for getting started (based on specifications, simplified for brevity):

```markdown
# Getting Started with bicep-whatif-advisor

Quick start guide for installation and basic usage.

## Installation

### Prerequisites

- Python 3.8 or higher
- Azure CLI
- An LLM provider API key

### Install Package

```bash
# With Anthropic Claude (recommended)
pip install bicep-whatif-advisor[anthropic]

# With Azure OpenAI
pip install bicep-whatif-advisor[azure]

# With all providers
pip install bicep-whatif-advisor[all]
```

### Set API Key

```bash
# Anthropic Claude
export ANTHROPIC_API_KEY=your-api-key

# Azure OpenAI
export AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
export AZURE_OPENAI_API_KEY=your-api-key
export AZURE_OPENAI_DEPLOYMENT=your-deployment-name
```

## First Analysis

1. **Generate What-If output:**

```bash
az deployment group what-if \
  --template-file main.bicep \
  --resource-group my-rg \
  --exclude-change-types NoChange Ignore
```

2. **Pipe to bicep-whatif-advisor:**

```bash
az deployment group what-if ... | bicep-whatif-advisor
```

3. **View results** in formatted table.

## Output Formats

### Table (default)

Human-readable colored table for terminal viewing.

### JSON

```bash
bicep-whatif-advisor --format json | jq '.resources[]'
```

### Markdown

```bash
bicep-whatif-advisor --format markdown > review.md
```

## Next Steps

- [CI/CD Integration Guide](CICD_INTEGRATION.md)
- [Risk Assessment Guide](RISK_ASSESSMENT.md)
- [CLI Reference](CLI_REFERENCE.md)
```

#### Step 5.3: docs/guides/CICD_INTEGRATION.md

Create CI/CD integration guide (summarized):

```markdown
# CI/CD Integration Guide

Set up automated deployment safety gates with bicep-whatif-advisor.

## GitHub Actions

### Basic Setup

```yaml
name: Infrastructure Deployment

on:
  pull_request:
    paths:
      - '**.bicep'

permissions:
  pull-requests: write

jobs:
  whatif-review:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install bicep-whatif-advisor
        run: pip install bicep-whatif-advisor[anthropic]

      - name: Run What-If and AI Review
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          az deployment group what-if \
            --template-file main.bicep \
            --resource-group rg-prod \
            --exclude-change-types NoChange Ignore \
            | bicep-whatif-advisor --ci --post-comment
```

## Azure DevOps

```yaml
trigger:
  branches:
    include:
      - main

pool:
  vmImage: ubuntu-latest

steps:
- checkout: self
  persistCredentials: true

- task: AzureCLI@2
  inputs:
    azureSubscription: 'my-service-connection'
    scriptType: 'bash'
    scriptLocation: 'inlineScript'
    inlineScript: |
      pip install bicep-whatif-advisor[anthropic]

      az deployment group what-if \
        --template-file main.bicep \
        --resource-group rg-prod \
        --exclude-change-types NoChange Ignore \
        | bicep-whatif-advisor --ci --post-comment
  env:
    ANTHROPIC_API_KEY: $(ANTHROPIC_API_KEY)
    SYSTEM_ACCESSTOKEN: $(System.AccessToken)
```

## Configuration

### Risk Thresholds

```bash
bicep-whatif-advisor --ci \
  --drift-threshold medium \
  --intent-threshold high \
  --operations-threshold medium
```

### Noise Filtering

```bash
bicep-whatif-advisor --ci \
  --noise-filter .github/whatif-noise-patterns.txt
```

## Exit Codes

- `0`: Safe deployment
- `1`: Unsafe deployment (blocks PR merge)
- `2`: Error (invalid input, missing API key, etc.)
```

### Task 6: Coverage Testing

Add coverage tool to dev dependencies in `pyproject.toml`:

```toml
[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-mock>=3.10.0",
    "pytest-cov>=4.0.0",
]
```

Run coverage:

```bash
# Install with coverage tool
pip install -e .[all,dev]

# Run tests with coverage
pytest --cov=bicep_whatif_advisor --cov-report=html --cov-report=term-missing

# View HTML report
open htmlcov/index.html
```

**Target:** 80% minimum coverage

**Critical paths requiring 100% coverage:**
- Input validation (TTY, What-If markers)
- Risk bucket evaluation
- Threshold comparison
- Confidence filtering

## Validation Checklist

- [ ] All fixture files created (create_only, mixed_changes, deletes, no_changes, large_output)
- [ ] Fixture generator script works
- [ ] Unit tests created for input module
- [ ] Unit tests created for prompt module
- [ ] Unit tests created for render module
- [ ] Unit tests created for CLI module
- [ ] Unit tests created for platform detection
- [ ] Unit tests created for risk buckets
- [ ] Unit tests created for noise filtering
- [ ] Unit tests created for PR comments
- [ ] Integration tests created for standard mode
- [ ] Integration tests created for CI mode
- [ ] Integration tests created for noise filtering
- [ ] All tests pass
- [ ] pytest configuration in pyproject.toml
- [ ] Coverage tool configured
- [ ] Code coverage â‰¥ 80%
- [ ] Critical paths have 100% coverage
- [ ] README.md created
- [ ] Getting Started guide created
- [ ] CI/CD Integration guide created
- [ ] Risk Assessment guide created (reference specification)
- [ ] CLI Reference created (reference specification)
- [ ] All documentation links work
- [ ] Code examples in docs are tested
- [ ] Installation instructions verified
- [ ] CI/CD examples verified

## Final Validation

### Complete Workflow Test

1. **Install package:**
   ```bash
   pip install -e .[all,dev]
   ```

2. **Run all tests:**
   ```bash
   pytest -v
   ```

3. **Check coverage:**
   ```bash
   pytest --cov=bicep_whatif_advisor --cov-report=term-missing
   ```

4. **Test standard mode:**
   ```bash
   cat tests/fixtures/create_only.txt | bicep-whatif-advisor
   ```

5. **Test CI mode:**
   ```bash
   cat tests/fixtures/mixed_changes.txt | bicep-whatif-advisor --ci
   ```

6. **Test noise filtering:**
   ```bash
   echo "Computed property change" > /tmp/patterns.txt
   cat tests/fixtures/mixed_changes.txt | bicep-whatif-advisor --noise-filter /tmp/patterns.txt
   ```

7. **Test all output formats:**
   ```bash
   cat tests/fixtures/create_only.txt | bicep-whatif-advisor --format table
   cat tests/fixtures/create_only.txt | bicep-whatif-advisor --format json
   cat tests/fixtures/create_only.txt | bicep-whatif-advisor --format markdown
   ```

8. **Verify package build:**
   ```bash
   python -m build
   ls dist/
   ```

## Project Complete!

Once all validation steps pass:

1. All 6 phases implemented âœ…
2. Tests passing with 80%+ coverage âœ…
3. Documentation complete âœ…
4. Package builds successfully âœ…
5. Ready for PyPI publication ðŸŽ‰

## Notes

- Use pytest-mock for cleaner mock syntax
- Never require real API keys for tests
- Keep tests fast (< 10 seconds total)
- All tests must be deterministic (no flaky tests)
- Mock all external dependencies (git, API calls, file I/O where appropriate)
- Use tmp_path fixture for temporary file operations
- Parametrize tests for multiple input variations
- Write defensive tests for all error paths
